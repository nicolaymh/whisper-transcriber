# Whisper Transcriber

Transcriptor **robusto** de mÃºltiples audios a texto y subtÃ­tulos usando [`faster-whisper`](https://github.com/guillaumekln/faster-whisper) (aprovecha GPU si estÃ¡ disponible), con limpieza automÃ¡tica del texto y generaciÃ³n de `.srt`. Funciona tanto en **GPU con CUDA** como en **CPU**.

---

## ğŸš€ CaracterÃ­sticas clave
- **Batch**: procesa todos los audios dentro de `audios/` y guarda resultados en `transcripciones/`.
- **Modelos Whisper**: intenta `large-v3` y, si falla, retrocede a `large-v2` automÃ¡ticamente.
- **OptimizaciÃ³n automÃ¡tica**: autodetecta CUDA; usa `float16` en GPU y `int8` en CPU.
- **Filtrado de ruido/no-voz**: VAD activado y umbrales para evitar repeticiones o texto espurio.
- **Post-procesado avanzado**: limpia basura, deduplica lÃ­neas y colapsa palabras repetidas.
- **Salida doble**: genera **TXT** con cabecera y **SRT** con marcas de tiempo.
- **GestiÃ³n de memoria**: liberaciÃ³n explÃ­cita de cachÃ© en GPU por iteraciÃ³n.

---

## ğŸ“¦ Requisitos e instalaciÃ³n

### 1) Python
- **Python 3.10+** recomendado.

### 2) LibrerÃ­as Python
Instala la dependencia principal directamente:

```bash
pip install faster-whisper
```

> `faster-whisper` instala internamente `ctranslate2`, `tokenizers`, etc. Si tu entorno no tiene **PyTorch** y deseas soporte para GPU (detecciÃ³n de CUDA y limpieza de cachÃ©), instala PyTorch segÃºn tu plataforma. Para CPU, **no es obligatorio** instalar PyTorch; el script seguirÃ¡ funcionando.

**Opcional â€“ PyTorch (GPU CUDA 12.x)**  
Si quieres soporte CUDA:
```bash
# CUDA 12.1 (ejemplo oficial de PyTorch)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**CPU Ãºnicamente (sin CUDA)**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

> Si no instalas `torch`, el script seguirÃ¡ funcionando porque hace comprobaciones seguras. Solo perderÃ¡s la limpieza explÃ­cita de cachÃ© CUDA.

### 3) FFmpeg
Necesitas **FFmpeg** para soportar mÃºltiples formatos de audio.

- **Ubuntu/Debian**
  ```bash
  sudo apt update && sudo apt install -y ffmpeg
  ```
- **Windows**
  - Descarga desde <https://ffmpeg.org/download.html>, agrega `ffmpeg.exe` a tu **PATH**.
- **macOS (Homebrew)**
  ```bash
  brew install ffmpeg
  ```

---

## ğŸ—‚ï¸ Estructura de carpetas
```
.
â”œâ”€â”€ audios/                 # â‡¦ coloca aquÃ­ tus .mp3, .wav, .m4a, .opus, .ogg
â”œâ”€â”€ transcripciones/        # â‡¦ se recrea en cada ejecuciÃ³n (se borra si ya existe)
â”œâ”€â”€ transcribe.py           # script principal (el algoritmo provisto)
â””â”€â”€ README.md               # este archivo
```

> âš ï¸ **Ojo**: el script elimina `transcripciones/` al inicio para empezar limpio:
> ```python
> if OUT_DIR.exists():
>     shutil.rmtree(OUT_DIR)
> OUT_DIR.mkdir(parents=True, exist_ok=True)
> ```
> Haz copia si no quieres perder resultados anteriores.

---

## â–¶ï¸ Uso
1. Coloca tus audios dentro de `audios/` (se procesan en orden â€œnaturalâ€, p. ej. `1_intro.mp3`, `2_parte.mp3`, ...).
2. Ejecuta:
   ```bash
   python transcribe.py
   ```
3. Revisa la carpeta `transcripciones/`:
   - `N - <nombre>.txt` â†’ texto con cabecera y duraciÃ³n total del audio.
   - `N - <nombre>.srt` â†’ subtÃ­tulos con timestamps precisos.

### Ejemplo de salida `.txt`
```
1 - entrevista_audio
DuraciÃ³n: 00:42:17

TranscripciÃ³n:

[Primeras lÃ­neas limadas por post-procesado...]
```

---

## ğŸ§© Opciones de modelo disponibles

`faster-whisper` soporta varios modelos de distinto tamaÃ±o y consumo.  
En el script por defecto se usa **large-v3** (mÃ¡xima precisiÃ³n), con retroceso a **large-v2**,  
pero puedes cambiarlos en la variable `MODEL_NAME` al inicio.

Modelos soportados:

- `tiny` â†’ muy rÃ¡pido, bajo consumo. Menor precisiÃ³n.
- `base` â†’ rÃ¡pido, precisiÃ³n aceptable.
- `small` â†’ buen equilibrio entre velocidad y calidad.
- `medium` â†’ alta precisiÃ³n, requiere mÃ¡s memoria.
- `large-v2` â†’ muy preciso, recomendado si tienes GPU/CPU potentes.
- `large-v3` â†’ versiÃ³n mÃ¡s reciente y precisa (por defecto en este script).

ğŸ‘‰ Ajusta en `transcribe.py`:
```python
MODEL_NAME = "small"
```
para usar el modelo que mejor se adapte a tu hardware.

---

## âš™ï¸ ParÃ¡metros importantes del algoritmo

### SelecciÃ³n de dispositivo y precisiÃ³n
```python
device = "cuda" if torch.cuda.is_available() else "cpu"
compute_type = "float16" if device == "cuda" else "int8"  # GPU=fp16, CPU=int8
```
- **GPU**: usa `float16` (rÃ¡pido y eficiente en VRAM).
- **CPU**: usa `int8` para reducir consumo de memoria.

### Modelo Whisper
```python
MODEL_NAME = "large-v3"
try:
    model = WhisperModel(MODEL_NAME, device=device, compute_type=compute_type)
except Exception:
    MODEL_NAME = "large-v2"
    model = WhisperModel(MODEL_NAME, device=device, compute_type=compute_type)
```
- Intenta `large-v3` y hace **fallback** a `large-v2` si falla (falta de RAM/VRAM o descarga interrumpida).

### ConfiguraciÃ³n de transcripciÃ³n
```python
segments, info = model.transcribe(
    str(audio_file),
    language="es",
    vad_filter=True,
    vad_parameters={"min_silence_duration_ms": 500},
    condition_on_previous_text=False,
    temperature=0.0,
    no_speech_threshold=0.6,
    compression_ratio_threshold=2.4,
    beam_size=5,
)
```
- **`language="es"`**: fuerza espaÃ±ol (ajÃºstalo si es otro idioma).
- **`vad_filter`**: filtra silencios/mÃºsica, Ãºtil para radio/pÃ³dcast.
- **`condition_on_previous_text=False`**: evita â€œmemoriaâ€ entre segmentos (reduce arrastre de errores).
- **`temperature=0.0`**: resultados mÃ¡s estables.
- **`no_speech_threshold` y `compression_ratio_threshold`**: descartan no-voz y texto raro.
- **`beam_size=5`**: decodificaciÃ³n robusta (mÃ¡s lenta que greedy, pero mejor).

### Post-procesado del texto
- **`limpiar_basura`**: elimina frases comunes no deseadas (ej. Amara.org).
- **`dedupe_lines`**: quita repeticiones de lÃ­neas consecutivas.
- **`colapsar_palabras_repetidas`**: comprime â€œhola hola holaâ€ â†’ â€œholaâ€.
- Fixes ligeros de espaciado en puntuaciÃ³n.

### GeneraciÃ³n de SRT
Timestamps en formato `HH:MM:SS,mmm` con precisiÃ³n milisegundos:
```python
00:00:00,000 --> 00:00:04,120
Texto del segmento 1
```

### Orden natural de archivos
Se aplica un **orden natural** para que `1_intro`, `2_parte`, `10_extra` queden bien ordenados.

---

## ğŸ”§ PersonalizaciÃ³n rÃ¡pida
- **Idioma**: cambia `language="es"` por el cÃ³digo ISO deseado.
- **Modelo**: sustituye `MODEL_NAME` por `tiny`, `base`, `small`, `medium`, `large-v2`, etc.
- **VAD**: ajusta `min_silence_duration_ms` (p. ej. 300 para cortes mÃ¡s finos).
- **Carpetas**: modifica `AUDIO_DIR` y `OUT_DIR` al inicio del script.

---

## ğŸ“ˆ Rendimiento y VRAM
- **GPU 8â€“12 GB**: `large-v2` suele ir cÃ³modo; `large-v3` puede requerir cerrar apps.
- **GPU modesta o CPU**: considera `small` o `medium` para mayor velocidad con precisiÃ³n aceptable.
- Si te quedas sin VRAM: usa `large-v2` o un modelo mÃ¡s pequeÃ±o.
- En **CPU**, el tiempo crecerÃ¡ considerablemente; `tiny`, `base` o `small` son mÃ¡s prÃ¡cticos.

---

## ğŸ§ª SoluciÃ³n de problemas

**1) â€œCUDA not availableâ€ o PyTorch no detecta GPU**  
- Verifica controladores NVIDIA + versiÃ³n CUDA compatible con tu PyTorch (`torch.version.cuda`).
- Instala la build correcta de PyTorch para tu CUDA (ver arriba).

**2) â€œffmpeg not foundâ€**  
- AsegÃºrate de tener FFmpeg instalado y en el `PATH` del sistema.

**3) â€œOut of memoryâ€ (VRAM)**  
- Cambia a un modelo mÃ¡s pequeÃ±o (`medium`, `small`, etc.).
- Cierra otros procesos que usen GPU.
- Reduce simultaneidad (no aplicable si procesas 1 archivo a la vez).

**4) Descargas interrumpidas de modelos**  
- Borra la carpeta de cachÃ© de `faster-whisper/ctranslate2` y vuelve a ejecutar para re-descargar.

**5) Texto con repeticiones**  
- Ya se aplican filtros (`no_speech_threshold`, `compression_ratio_threshold`) y post-procesado. Ajusta umbrales si persiste.

---

## ğŸ“œ Licencia
Este proyecto se distribuye bajo **MIT** (puedes cambiarlo si tu repositorio usa otra).

## ğŸ™Œ CrÃ©ditos
- [faster-whisper](https://github.com/guillaumekln/faster-whisper) por su implementaciÃ³n eficiente de Whisper.
- OpenAI Whisper (modelo original).

---

## ğŸ“ Notas
- La carpeta `transcripciones/` se **recrea** en cada corrida (se borra si existÃ­a).
- El script muestra **progreso por archivo**, duraciÃ³n total transcrita y lista de errores si los hubiera.
