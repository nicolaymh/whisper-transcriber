# Whisper Transcriber

Transcriptor **robusto** de m√∫ltiples audios a texto y subt√≠tulos usando [`faster-whisper`](https://github.com/guillaumekln/faster-whisper) (aprovecha GPU si est√° disponible), con limpieza autom√°tica del texto y generaci√≥n de `.srt`. Funciona tanto en **GPU con CUDA** como en **CPU**.

---

## üöÄ Instalaci√≥n y Primer Uso

### Primera vez (configuraci√≥n inicial)
1. Clona el repo:
   ```bash
   git clone git@github.com:nicolaymh/whisper-transcriber.git
   cd whisper-transcriber
   ```

2. Crea el entorno e instala dependencias:
   - Con **GPU NVIDIA**:
     ```bash
     make setup
     make install-gpu
     make install-cudnn
     ```
   - Solo **CPU**:
     ```bash
     make setup
     make install-cpu
     ```

3. Coloca tus audios en la carpeta:
   ```bash
   audios/
   ```

4. Ejecuta la transcripci√≥n:
   ```bash
   make run
   ```

### Uso diario (despu√©s de la primera vez)
```bash
cd whisper-transcriber
make run
```

Los resultados se generan en `transcripciones/` como `.txt` y `.srt`.

---

## üöÄ Caracter√≠sticas clave
- **Batch**: procesa todos los audios dentro de `audios/` y guarda resultados en `transcripciones/`.
- **Modelos Whisper**: intenta `large-v3` y, si falla, retrocede a `large-v2` autom√°ticamente.
- **Optimizaci√≥n autom√°tica**: autodetecta CUDA; usa `float16` en GPU y `int8` en CPU.
- **Filtrado de ruido/no-voz**: VAD activado y umbrales para evitar repeticiones o texto espurio.
- **Post-procesado avanzado**: limpia basura, deduplica l√≠neas y colapsa palabras repetidas.
- **Salida doble**: genera **TXT** con cabecera y **SRT** con marcas de tiempo.
- **Gesti√≥n de memoria**: liberaci√≥n expl√≠cita de cach√© en GPU por iteraci√≥n.

---

## üì¶ Requisitos

Antes de usar el transcriptor aseg√∫rate de tener instalado:

### 1) Python
- **Python 3.10+** recomendado (el Makefile crear√° un entorno virtual `.venv/` con todas las librer√≠as necesarias).

### 2) FFmpeg
Necesario para soportar m√∫ltiples formatos de audio.

- **Ubuntu/Debian**
  ```bash
  sudo apt update && sudo apt install -y ffmpeg
  ```
- **Windows**
  Descarga desde <https://ffmpeg.org/download.html> y agrega `ffmpeg.exe` a tu **PATH**.
- **macOS (Homebrew)**
  ```bash
  brew install ffmpeg
  ```

### 3) Dependencias Python
No es necesario instalarlas manualmente.  
El **Makefile crea el entorno virtual y gestiona todas las dependencias** (`torch`, `faster-whisper`, `cudnn`, etc.).

> ‚ö° **Nota**: No necesitas ejecutar `source .venv/bin/activate`.  
> Cada comando `make` activa y usa el entorno virtual autom√°ticamente.

---

## üóÇÔ∏è Estructura de carpetas
```
.
‚îú‚îÄ‚îÄ audios/                 # ‚á¶ coloca aqu√≠ tus .mp3, .wav, .m4a, .opus, .ogg
‚îú‚îÄ‚îÄ transcripciones/        # ‚á¶ se recrea en cada ejecuci√≥n (se borra si ya existe)
‚îú‚îÄ‚îÄ transcribe.py           # script principal (el algoritmo provisto)
‚îî‚îÄ‚îÄ README.md               # este archivo
```

> ‚ö†Ô∏è **Ojo**: el script elimina `transcripciones/` al inicio para empezar limpio:
> ```python
> if OUT_DIR.exists():
>     shutil.rmtree(OUT_DIR)
> OUT_DIR.mkdir(parents=True, exist_ok=True)
> ```
> Haz copia si no quieres perder resultados anteriores.

---

## ‚ñ∂Ô∏è Uso
1. Coloca tus audios dentro de `audios/` (se procesan en orden ‚Äúnatural‚Äù, p. ej. `1_intro.mp3`, `2_parte.mp3`, ...).
2. Ejecuta:
   ```bash
   python transcribe.py
   ```
3. Revisa la carpeta `transcripciones/`:
   - `N - <nombre>.txt` ‚Üí texto con cabecera y duraci√≥n total del audio.
   - `N - <nombre>.srt` ‚Üí subt√≠tulos con timestamps precisos.

### Ejemplo de salida `.txt`
```
1 - entrevista_audio
Duraci√≥n: 00:42:17

Transcripci√≥n:

[Primeras l√≠neas limadas por post-procesado...]
```

---

## üß© Opciones de modelo disponibles

`faster-whisper` soporta varios modelos de distinto tama√±o y consumo.  
En el script por defecto se usa **large-v3** (m√°xima precisi√≥n), con retroceso a **large-v2**,  
pero puedes cambiarlos en la variable `MODEL_NAME` al inicio.

Modelos soportados:

- `tiny` ‚Üí muy r√°pido, bajo consumo. Menor precisi√≥n.
- `base` ‚Üí r√°pido, precisi√≥n aceptable.
- `small` ‚Üí buen equilibrio entre velocidad y calidad.
- `medium` ‚Üí alta precisi√≥n, requiere m√°s memoria.
- `large-v2` ‚Üí muy preciso, recomendado si tienes GPU/CPU potentes.
- `large-v3` ‚Üí versi√≥n m√°s reciente y precisa (por defecto en este script).

üëâ Ajusta en `transcribe.py`:
```python
MODEL_NAME = "small"
```
para usar el modelo que mejor se adapte a tu hardware.

---

## ‚öôÔ∏è Par√°metros importantes del algoritmo

### Selecci√≥n de dispositivo y precisi√≥n
```python
device = "cuda" if torch.cuda.is_available() else "cpu"
compute_type = "float16" if device == "cuda" else "int8"  # GPU=fp16, CPU=int8
```
- **GPU**: usa `float16` (r√°pido y eficiente en VRAM).
- **CPU**: usa `int8` para reducir consumo de memoria.

### Modelo Whisper
```python
MODEL_NAME = "large-v3"
try:
    model = WhisperModel(MODEL_NAME, device=device, compute_type=compute_type)
except Exception:
    MODEL_NAME = "large-v2"
    model = WhisperModel(MODEL_NAME, device=device, compute_type=compute_type)
```
- Intenta `large-v3` y hace **fallback** a `large-v2` si falla (falta de RAM/VRAM o descarga interrumpida).

### Configuraci√≥n de transcripci√≥n
```python
segments, info = model.transcribe(
    str(audio_file),
    language="es",
    vad_filter=True,
    vad_parameters={"min_silence_duration_ms": 500},
    condition_on_previous_text=False,
    temperature=0.0,
    no_speech_threshold=0.6,
    compression_ratio_threshold=2.4,
    beam_size=5,
)
```
- **`language="es"`**: fuerza espa√±ol (aj√∫stalo si es otro idioma).
- **`vad_filter`**: filtra silencios/m√∫sica, √∫til para radio/p√≥dcast.
- **`condition_on_previous_text=False`**: evita ‚Äúmemoria‚Äù entre segmentos (reduce arrastre de errores).
- **`temperature=0.0`**: resultados m√°s estables.
- **`no_speech_threshold` y `compression_ratio_threshold`**: descartan no-voz y texto raro.
- **`beam_size=5`**: decodificaci√≥n robusta (m√°s lenta que greedy, pero mejor).

### Post-procesado del texto
- **`limpiar_basura`**: elimina frases comunes no deseadas (ej. Amara.org).
- **`dedupe_lines`**: quita repeticiones de l√≠neas consecutivas.
- **`colapsar_palabras_repetidas`**: comprime ‚Äúhola hola hola‚Äù ‚Üí ‚Äúhola‚Äù.
- Fixes ligeros de espaciado en puntuaci√≥n.

### Generaci√≥n de SRT
Timestamps en formato `HH:MM:SS,mmm` con precisi√≥n milisegundos:
```python
00:00:00,000 --> 00:00:04,120
Texto del segmento 1
```

### Orden natural de archivos
Se aplica un **orden natural** para que `1_intro`, `2_parte`, `10_extra` queden bien ordenados.

---

## üîß Personalizaci√≥n r√°pida
- **Idioma**: cambia `language="es"` por el c√≥digo ISO deseado.
- **Modelo**: sustituye `MODEL_NAME` por `tiny`, `base`, `small`, `medium`, `large-v2`, etc.
- **VAD**: ajusta `min_silence_duration_ms` (p. ej. 300 para cortes m√°s finos).
- **Carpetas**: modifica `AUDIO_DIR` y `OUT_DIR` al inicio del script.

---

## üìà Rendimiento y VRAM
- **GPU 8‚Äì12 GB**: `large-v2` suele ir c√≥modo; `large-v3` puede requerir cerrar apps.
- **GPU modesta o CPU**: considera `small` o `medium` para mayor velocidad con precisi√≥n aceptable.
- Si te quedas sin VRAM: usa `large-v2` o un modelo m√°s peque√±o.
- En **CPU**, el tiempo crecer√° considerablemente; `tiny`, `base` o `small` son m√°s pr√°cticos.

---

## üß™ Soluci√≥n de problemas

**1) ‚ÄúCUDA not available‚Äù o PyTorch no detecta GPU**  
- Verifica controladores NVIDIA + versi√≥n CUDA compatible con tu PyTorch (`torch.version.cuda`).
- Instala la build correcta de PyTorch para tu CUDA (ver arriba).

**2) ‚Äúffmpeg not found‚Äù**  
- Aseg√∫rate de tener FFmpeg instalado y en el `PATH` del sistema.

**3) ‚ÄúOut of memory‚Äù (VRAM)**  
- Cambia a un modelo m√°s peque√±o (`medium`, `small`, etc.`).
- Cierra otros procesos que usen GPU.
- Reduce simultaneidad (no aplicable si procesas 1 archivo a la vez).

**4) Descargas interrumpidas de modelos**  
- Borra la carpeta de cach√© de `faster-whisper/ctranslate2` y vuelve a ejecutar para re-descargar.

**5) Texto con repeticiones**  
- Ya se aplican filtros (`no_speech_threshold`, `compression_ratio_threshold`) y post-procesado. Ajusta umbrales si persiste.

---

## üìú Licencia
Este proyecto se distribuye bajo **MIT** (puedes cambiarlo si tu repositorio usa otra).

## üôå Cr√©ditos
- [faster-whisper](https://github.com/guillaumekln/faster-whisper) por su implementaci√≥n eficiente de Whisper.
- OpenAI Whisper (modelo original).

---

## üìù Notas
- La carpeta `transcripciones/` se **recrea** en cada corrida (se borra si exist√≠a).
- El script muestra **progreso por archivo**, duraci√≥n total transcrita y lista de errores si los hubiera.
